<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration>
    <property>
    <name>http.agent.name</name>
    <value>CdiscountBot-crawler</value>
    </property>
 <property>
  <name>http.robots.agents</name>
  <value>*</value>
  <description>The agent strings we'll look for in robots.txt files,
  comma-separated, in decreasing order of precedence. You should
  put the value of http.agent.name as the first agent name, and keep the
  default * at the end of the list. E.g.: BlurflDev,Blurfl,*
  </description>
</property>
<property>
  <name>http.robots.403.allow</name>
  <value>true</value>
  <description>Some servers return HTTP status 403 (Forbidden) if
  /robots.txt doesn't exist. This should probably mean that we are
  allowed to crawl the site nonetheless. If this is set to false,
  then such sites will be treated as forbidden.</description>
</property>
<property>
  <name>http.agent.description</name>
  <value>xxx</value>
  <description>Further description of our bot</description>
</property>
<property>
  <name>http.agent.url</name>
  <value></value>
  <description>A URL to advertise in the User-Agent header.</description>
</property>
<property>
  <name>http.agent.email</name>
  <value></value>
  <description>An email address to advertise in the HTTP 'From' request
   header and User-Agent header. A good practice is to mangle this
   address (e.g. 'info at example dot com') to avoid spamming.
  </description>
</property>
<property>
  <name>http.agent.version</name>
  <value>Nutch-1.8</value>
  <description>A version string to advertise in the User-Agent 
   header.</description>
</property>
<property>
  <name>http.agent.host</name>
  <value></value>
  <description>Name or IP address of the host on which the Nutch crawler
  would be running.</description>
</property>
<property>
  <name>http.timeout</name>
  <value>100000</value>
  <description>The default network timeout, in milliseconds.</description>
</property>
<property>
  <name>http.max.delays</name>
  <value>100</value>
  <description>The number of times a thread will delay when trying to
  fetch a page.</description>
</property>
<property>
  <name>generate.max.count</name>
  <value>10000</value>
  <description>The maximum number of urls in a single
  fetchlist.  -1 if unlimited. The urls are counted according
  to the value of the parameter generator.count.mode.
  </description>
</property>

<!--   SQL back end for Nutch 2.x series
<property>
  <name>fetcher.store.content</name>
  <value>true</value>
  <description>If true, fetcher will store content.</description>
</property>
    <property>
    <name>http.accept.language</name>
    <value>zh-cn, ja-jp, en-us,en-gb,en;q=0.7,*;q=0.3</value>
    <description>Value of the “Accept-Language” request header field.
    This allows selecting non-English language as default one to retrieve.
    It is a useful setting for search engines build for certain national group.
    </description>
    </property>
    <property>
    <name>parser.character.encoding.default</name>
    <value>utf-8</value>
    <description>The character encoding to fall back to when no other information
    is available</description>
    </property>
    <property>
    <name>storage.data.store.class</name>
    <value>org.apache.gora.sql.store.SqlStore</value>
    <description>The Gora DataStore class for storing and retrieving data.
    Currently the following stores are available: ….
    </description>
    </property>
    
    -->
    
 <!-- linkrank scoring properties for the page rank algorithm -->
<property>
  <name>link.ignore.internal.host</name>
  <value>false</value>
  <description>Ignore outlinks to the same hostname.</description>
</property>

<property>
  <name>link.ignore.internal.domain</name>
  <value>false</value>
  <description>Ignore outlinks to the same domain.</description>
</property>

<property>
  <name>link.ignore.limit.page</name>
  <value>false</value>
  <description>Limit to only a single outlink to the same page.</description>
</property>

<property>
  <name>link.ignore.limit.domain</name>
  <value>false</value>
</property>

<property>
  <name>link.ignore.limit.domain</name>
  <value>false</value>
  <description>Limit to only a single outlink to the same domain.</description>
</property>

<!-- to parse metatags -->

<!-- old stuff from nutch 2.0
<property>
   <name>plugin.folders</name>
   <value>/data/apache-nutch-1.8/build/plugins</value>
</property>
<property>
        <name>plugin.includes</name>
        <value>protocol-http|protocol-httpclient|urlfilter-regex|parse-(html|tika|metatags)|index-(basic|anchor|metadata)|scoring-opic|urlnormalizer-(pass|regex|basic)</value>
</property> 

<property>
        <name>metatags.names</name>
        <value>*</value>
</property>


<property>
        <name>index.parse.md</name>
        <value>metatag.description,metatag.author,metatag.twitter:image</value>
</property>
<property>
        <name>index.content.md</name>
        <value>author,description,twitter:image</value>
</property>

-->
<property>
<name>plugin.includes</name>
<value>protocol-http|urlfilter-regex|parse-(html|tika|metatags)|index-(basic|anchor|metadata)|indexer-solr|scoring-opic|urlnormalizer-(pass|regex|basic)</value>
</property>
<!-- Used only if plugin parse-metatags is enabled. -->
<property>
<name>metatags.names</name>
<value>description;h1</value>
<description> Names of the metatags to extract, separated by;.
  Use '*' to extract all metatags. Prefixes the names with 'metatag.'
  in the parse-metadata. For instance to index description and keywords,
  you need to activate the plugin index-metadata and set the value of the
  parameter 'index.parse.md' to 'metatag.description;metatag.keywords'.
</description>
</property>

<property>
  <name>index.parse.md</name>
  <value>metatag.description,metatag.h1</value>
  <description>
  Comma-separated list of keys to be taken from the parse metadata to generate fields.
  Can be used e.g. for 'description' or 'keywords' provided that these values are generated
  by a parser (see parse-metatags plugin)
  </description>
</property>

 <property>
   <name>db.max.outlinks.per.page</name>
   <value>-1</value>
   <description>The maximum number of outlinks that we'll process for a page.
   If this value is nonnegative (>=0), at most db.max.outlinks.per.page outlinks
   will be processed for a page; otherwise, all outlinks will be processed.
   </description>
 </property>
 
<!-- number of threads --> 

<!-- we dont have here to limit our host cdiscount
<property>
  <name>fetcher.threads.per.host</name>
  <value>300</value>
  <description>This number is the maximum number of threads that
    should be allowed to access a host at one time.</description>
</property> 
--> 
<property>
 <name>fetcher.server.delay</name>
 <value>0.0</value>
</property>
<property>
 <name>fetcher.threads.fetch</name>
 <value>300</value>
</property>
<!--<property>
 <name>fetcher.threads.per.queue</name>
 <value>200</value>
</property> -->

<property>
  <name>http.timeout</name>
  <value>10000000000000</value>
  <description>The default network timeout, in milliseconds.</description>
</property>

<!-- web db properties -->

<property>
  <name>db.default.fetch.interval</name>
  <value>30</value>
  <description>(DEPRECATED) The default number of days between re-fetches of a page.
  </description>
</property>

<property>
  <name>db.fetch.interval.default</name>
  <value>2592000</value>
  <description>The default number of seconds between re-fetches of a page (30 days).
  </description>
</property>

<property>
  <name>db.fetch.interval.max</name>
  <value>7776000</value>
  <description>The maximum number of seconds between re-fetches of a page
  (90 days). After this period every page in the db will be re-tried, no
  matter what is its status.
  </description>
</property>

<property>
  <name>db.fetch.schedule.class</name>
  <value>org.apache.nutch.crawl.DefaultFetchSchedule</value>
  <description>The implementation of fetch schedule. DefaultFetchSchedule simply
  adds the original fetchInterval to the last fetch time, regardless of
  page changes.</description>
</property>

<property>
  <name>db.fetch.schedule.adaptive.inc_rate</name>
  <value>0.4</value>
  <description>If a page is unmodified, its fetchInterval will be
  increased by this rate. This value should not
  exceed 0.5, otherwise the algorithm becomes unstable.</description>
</property>

<property>
  <name>db.fetch.schedule.adaptive.dec_rate</name>
  <value>0.2</value>
  <description>If a page is modified, its fetchInterval will be
  decreased by this rate. This value should not
  exceed 0.5, otherwise the algorithm becomes unstable.</description>
</property>

<property>
  <name>db.fetch.schedule.adaptive.min_interval</name>
  <value>60.0</value>
  <description>Minimum fetchInterval, in seconds.</description>
</property>

<property>
  <name>db.fetch.schedule.adaptive.max_interval</name>
  <value>31536000.0</value>
  <description>Maximum fetchInterval, in seconds (365 days).
  NOTE: this is limited by db.fetch.interval.max. Pages with
  fetchInterval larger than db.fetch.interval.max
  will be fetched anyway.</description>
</property>

<property>
  <name>db.fetch.schedule.adaptive.sync_delta</name>
  <value>true</value>
  <description>If true, try to synchronize with the time of page change.
  by shifting the next fetchTime by a fraction (sync_rate) of the difference
  between the last modification time, and the last fetch time.</description>
</property>

<property>
  <name>db.fetch.schedule.adaptive.sync_delta_rate</name>
  <value>0.3</value>
  <description>See sync_delta for description. This value should not
  exceed 0.5, otherwise the algorithm becomes unstable.</description>
</property>

<property>
  <name>db.update.additions.allowed</name>
  <value>true</value>
  <description>If true, updatedb will add newly discovered URLs, if false
  only already existing URLs in the CrawlDb will be updated and no new
  URLs will be added.
  </description>
</property>

<!--
Hadoop file system property
-->
<!--
<property>
  <name>hadoop.tmp.dir</name>
  <value>/data/apache-nutch-1.8/nutch_results/tmp</value> 
</property>
-->

</configuration>